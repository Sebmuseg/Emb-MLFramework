\chapter{Diskussion}
\label{chap:diskussion}

Dieses Kapitel diskutiert die wichtigsten Ergebnisse des entwickelten Frameworks sowie die Herausforderungen, die während der Implementierung 
und Evaluation auftraten. Dabei werden auch mögliche Verbesserungen und Erweiterungen für zukünftige Arbeiten aufgezeigt. 
Ziel dieser Diskussion ist es, die Leistung des Frameworks in Bezug auf die gesetzten Anforderungen zu bewerten und Potenziale für zukünftige 
Optimierungen und Erweiterungen zu identifizieren.

Die Evaluation zeigt, dass die gewählten Optimierungstechniken und das modulare Design erfolgreich umgesetzt wurden, um 
Echtzeitanforderungen und Ressourceneffizienz in der industriellen Fertigung zu gewährleisten. Zusammenfassend werden die zentralen Erkenntnisse, 
Herausforderungen und Verbesserungspotenziale erläutert.

\textbf{Erfüllung der Echtzeitanforderungen:} Ein wesentliches Ziel bestand darin, die Echtzeitfähigkeit für industrielle Anwendungen 
sicherzustellen. Die Ergebnisse bestätigen, dass das Framework die definierten Latenzanforderungen erfüllt. Optimierungstechniken wie Quantisierung 
und Pruning trugen signifikant zur Reduktion der Modellgröße bei, was die Vorhersagegeschwindigkeit und die Latenz positiv beeinflusste. 
Selbst bei ressourcenbeschränkten Geräten, wie Mikrocontrollern und SPS-Systemen, blieb die Latenz in tolerierbaren Grenzen, wodurch die 
Anwendbarkeit des Frameworks in der Praxis belegt wird.

\textbf{Ressourceneffizienz und Speicherverbrauch:} Um Modelle auf Geräten mit begrenztem Speicher wie SPS und Mikrocontrollern betreiben zu können, 
stellte die Reduktion des Speicherverbrauchs eine zentrale Anforderung dar. Die Quantisierung zeigte hier die größte Wirkung, mit einer Speichereinsparung 
von bis zu 70\% ohne signifikanten Einfluss auf die Modellgenauigkeit. Dies ermöglicht den Einsatz komplexerer Modelle auf stark ressourcenbeschränkten 
Plattformen und erweitert die Einsatzmöglichkeiten des Frameworks in der industriellen Fertigung.

\textbf{Modellgenauigkeit und Robustheit:} Die Modellgenauigkeit blieb trotz der angewandten Optimierungen überwiegend erhalten. 
Leichte Abnahmen der Genauigkeit traten insbesondere bei Modellen ohne Quantization-Aware Training (QAT) auf. In den meisten industriellen Anwendungen 
ist diese geringfügige Abweichung jedoch tolerierbar. Darüber hinaus zeigt die Evaluation, dass das Framework robust gegenüber verrauschten Eingabedaten bleibt, 
was in Echtzeitsystemen essenziell ist.

\textbf{Herausforderungen und Lessons Learned:} Die Entwicklung und Implementierung des Frameworks waren mit verschiedenen Herausforderungen verbunden, 
insbesondere durch die Anpassung an unterschiedliche Hardware-Ressourcen. Mikrocontroller und SPS-Systeme verfügen über begrenzte Rechenleistung und Speicher, 
wodurch eine Balance zwischen Modellgröße und Genauigkeit notwendig war. Während Pruning und Quantisierung zur Reduktion des Ressourcenverbrauchs beitrugen, 
führten sie in bestimmten Fällen zu Genauigkeitsverlusten und einer nichtlinearen Reduktion der Ausführungszeit. 
Das Prinzip der \textbf{Single Responsibility Principle (SRP)} erwies sich dabei als essenziell, um die Modularität und Wartbarkeit des 
Frameworks sicherzustellen und vorhandene Komponenten effizient zu nutzen, indem sie in klar umgrenzte Wrapper integriert wurden. 

\textbf{Technologische Überlegungen:} Die Programmiersprache \textbf{Rust} wurde aufgrund ihrer hohen Einstiegshürde und des begrenzten Supports 
in der Zielumgebung ausgeschlossen, jedoch bietet sie langfristig Potenzial für sicherheitskritische Anwendungen, in denen Memory-Safety eine Priorität ist. 
Auch ist das Framework derzeit vor allem für Brownfield-Umgebungen gedacht, wo ältere Maschinen und Systeme ohne integrierte ML-Kapazitäten aufgerüstet werden. 
Moderne, leistungsstarke Anlagen bieten zunehmend integrierte ML-Support und Hardware für effiziente Modelldepoyments. Die zeitliche Gültigkeit des Frameworks 
lässt sich durch Docker oder eine native Python-Umgebung verlängern, sodass auch zukünftige Brownfield-Installationen profitieren.

\textbf{Zusammenfassung der Diskussion:} Die Implementierung und Evaluation des Frameworks bestätigen, dass Machine-Learning-Modelle erfolgreich auf 
ressourcenbeschränkten Embedded-Systemen eingesetzt werden können. Trotz Herausforderungen wie der Anpassung an unterschiedliche Hardware und dem Umgang mit 
Optimierungstechniken konnte das Framework die Anforderungen an Echtzeitfähigkeit und Ressourceneffizienz erfüllen. Zukünftige Arbeiten könnten sich auf die 
Verfeinerung der Modelloptimierung, die Erweiterung der Hardwareunterstützung und die Verbesserung der Effizienz in Echtzeitsystemen konzentrieren.